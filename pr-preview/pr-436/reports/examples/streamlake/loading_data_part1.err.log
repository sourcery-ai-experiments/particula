Traceback (most recent call last):
  File "/opt/hostedtoolcache/Python/3.11.8/x64/lib/python3.11/site-packages/jupyter_cache/executors/utils.py", line 58, in single_nb_execution
    executenb(
  File "/opt/hostedtoolcache/Python/3.11.8/x64/lib/python3.11/site-packages/nbclient/client.py", line 1314, in execute
    return NotebookClient(nb=nb, resources=resources, km=km, **kwargs).execute()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/hostedtoolcache/Python/3.11.8/x64/lib/python3.11/site-packages/jupyter_core/utils/__init__.py", line 165, in wrapped
    return loop.run_until_complete(inner)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/hostedtoolcache/Python/3.11.8/x64/lib/python3.11/asyncio/base_events.py", line 654, in run_until_complete
    return future.result()
           ^^^^^^^^^^^^^^^
  File "/opt/hostedtoolcache/Python/3.11.8/x64/lib/python3.11/site-packages/nbclient/client.py", line 709, in async_execute
    await self.async_execute_cell(
  File "/opt/hostedtoolcache/Python/3.11.8/x64/lib/python3.11/site-packages/nbclient/client.py", line 1062, in async_execute_cell
    await self._check_raise_for_error(cell, cell_index, exec_reply)
  File "/opt/hostedtoolcache/Python/3.11.8/x64/lib/python3.11/site-packages/nbclient/client.py", line 918, in _check_raise_for_error
    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)
nbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:
------------------
# Importing the loader interface from the particula package
from particula.data import loader_interface
from particula.data.tests.example_data.get_example_data import get_data_folder

# Getting the working path where the data files are located
working_path = get_data_folder()

# Defining the settings for loading CPC 3010 data
# These settings were previously generated or can be created manually
cpc_settings = {
    # Folder name containing the data files
    'relative_data_folder': 'CPC_3010_data',
    # Pattern to match filenames (e.g., all CSV files)
    'filename_regex': '*.csv',
    'MIN_SIZE_BYTES': 10,  # Minimum file size in bytes for a file to be considered
    # Function to be used for loading the data
    'data_loading_function': 'general_1d_load',
    'header_row': 0,  # Row number of the header in the data file
    'data_checks': {
        # Range of character count per line (min, max)
        'characters': [10, 100],
        # Number of times a character (comma) should appear in each line
        'char_counts': {',': 4},
        'skip_rows': 0,  # Number of rows to skip at the beginning of the file
        'skip_end': 0  # Number of rows to skip at the end of the file
    },
    'data_column': [1, 2],  # Columns in the file that contain the data
    'data_header': ['data 1', 'data 2'],  # Headers for the data columns
    'time_column': [0],  # Column in the file that contains the time data
    'time_format': 'epoch',  # Format of the time data (epoch, ISO 8601, etc.)
    'delimiter': ',',  # Delimiter used in the data file (e.g., comma for CSV)
    'time_shift_seconds': 0,  # Shift in time data if needed, in seconds
    'timezone_identifier': 'UTC'  # Timezone identifier for the time data
}

# Now call the loader interface to load the data using the specified settings
data_stream = loader_interface.load_files_interface(
    path=working_path,  # Path to the data folder
    settings=cpc_settings,  # Settings defined above
)

# The data_stream object now contains the loaded and formatted data ready
# for analysis
------------------

----- stdout -----
  Loading file: CPC_3010_data_20220710_Jul.csv
----- stdout -----
  Loading file: CPC_3010_data_20220709_Jul.csv
------------------

[0;31m---------------------------------------------------------------------------[0m
[0;31mMemoryError[0m                               Traceback (most recent call last)
Cell [0;32mIn[8], line 37[0m
[1;32m     10[0m cpc_settings [38;5;241m=[39m {
[1;32m     11[0m     [38;5;66;03m# Folder name containing the data files[39;00m
[1;32m     12[0m     [38;5;124m'[39m[38;5;124mrelative_data_folder[39m[38;5;124m'[39m: [38;5;124m'[39m[38;5;124mCPC_3010_data[39m[38;5;124m'[39m,
[0;32m   (...)[0m
[1;32m     33[0m     [38;5;124m'[39m[38;5;124mtimezone_identifier[39m[38;5;124m'[39m: [38;5;124m'[39m[38;5;124mUTC[39m[38;5;124m'[39m  [38;5;66;03m# Timezone identifier for the time data[39;00m
[1;32m     34[0m }
[1;32m     36[0m [38;5;66;03m# Now call the loader interface to load the data using the specified settings[39;00m
[0;32m---> 37[0m data_stream [38;5;241m=[39m [43mloader_interface[49m[38;5;241;43m.[39;49m[43mload_files_interface[49m[43m([49m
[1;32m     38[0m [43m    [49m[43mpath[49m[38;5;241;43m=[39;49m[43mworking_path[49m[43m,[49m[43m  [49m[38;5;66;43;03m# Path to the data folder[39;49;00m
[1;32m     39[0m [43m    [49m[43msettings[49m[38;5;241;43m=[39;49m[43mcpc_settings[49m[43m,[49m[43m  [49m[38;5;66;43;03m# Settings defined above[39;49;00m
[1;32m     40[0m [43m)[49m
[1;32m     42[0m [38;5;66;03m# The data_stream object now contains the loaded and formatted data ready[39;00m
[1;32m     43[0m [38;5;66;03m# for analysis[39;00m

File [0;32m/opt/hostedtoolcache/Python/3.11.8/x64/lib/python3.11/site-packages/particula/data/loader_interface.py:157[0m, in [0;36mload_files_interface[0;34m(path, settings, stream, sub_sample)[0m
[1;32m    154[0m [38;5;28mprint[39m([38;5;124m'[39m[38;5;124m  Loading file:[39m[38;5;124m'[39m, file_info[file_i][[38;5;241m0[39m])
[1;32m    156[0m [38;5;28;01mif[39;00m settings[[38;5;124m'[39m[38;5;124mdata_loading_function[39m[38;5;124m'[39m] [38;5;241m==[39m [38;5;124m'[39m[38;5;124mgeneral_1d_load[39m[38;5;124m'[39m:
[0;32m--> 157[0m     stream [38;5;241m=[39m [43mget_1d_stream[49m[43m([49m
[1;32m    158[0m [43m        [49m[43mfile_path[49m[38;5;241;43m=[39;49m[43mfile_path[49m[43m,[49m
[1;32m    159[0m [43m        [49m[43mfirst_pass[49m[38;5;241;43m=[39;49m[43mfirst_pass[49m[43m,[49m
[1;32m    160[0m [43m        [49m[43msettings[49m[38;5;241;43m=[39;49m[43msettings[49m[43m,[49m
[1;32m    161[0m [43m        [49m[43mstream[49m[38;5;241;43m=[39;49m[43mstream[49m
[1;32m    162[0m [43m    [49m[43m)[49m
[1;32m    164[0m [38;5;28;01melif[39;00m settings[[38;5;124m'[39m[38;5;124mdata_loading_function[39m[38;5;124m'[39m] [38;5;241m==[39m [38;5;124m'[39m[38;5;124mgeneral_2d_load[39m[38;5;124m'[39m:
[1;32m    165[0m     stream [38;5;241m=[39m get_2d_stream(
[1;32m    166[0m         file_path[38;5;241m=[39mfile_path,
[1;32m    167[0m         first_pass[38;5;241m=[39mfirst_pass,
[1;32m    168[0m         settings[38;5;241m=[39msettings,
[1;32m    169[0m         stream[38;5;241m=[39mstream
[1;32m    170[0m     )

File [0;32m/opt/hostedtoolcache/Python/3.11.8/x64/lib/python3.11/site-packages/particula/data/loader_interface.py:328[0m, in [0;36mget_1d_stream[0;34m(file_path, settings, first_pass, stream)[0m
[1;32m    326[0m     stream[38;5;241m.[39mtime [38;5;241m=[39m epoch_time
[1;32m    327[0m [38;5;28;01melse[39;00m:
[0;32m--> 328[0m     stream [38;5;241m=[39m [43mmerger[49m[38;5;241;43m.[39;49m[43mstream_add_data[49m[43m([49m
[1;32m    329[0m [43m        [49m[43mstream[49m[38;5;241;43m=[39;49m[43mstream[49m[43m,[49m
[1;32m    330[0m [43m        [49m[43mtime_new[49m[38;5;241;43m=[39;49m[43mepoch_time[49m[43m,[49m
[1;32m    331[0m [43m        [49m[43mdata_new[49m[38;5;241;43m=[39;49m[43mdata[49m[43m,[49m
[1;32m    332[0m [43m        [49m[43mheader_check[49m[38;5;241;43m=[39;49m[38;5;28;43;01mTrue[39;49;00m[43m,[49m
[1;32m    333[0m [43m        [49m[43mheader_new[49m[38;5;241;43m=[39;49m[43msettings[49m[43m[[49m[38;5;124;43m'[39;49m[38;5;124;43mdata_header[39;49m[38;5;124;43m'[39;49m[43m][49m
[1;32m    334[0m [43m    [49m[43m)[49m
[1;32m    335[0m [38;5;28;01mreturn[39;00m stream

File [0;32m/opt/hostedtoolcache/Python/3.11.8/x64/lib/python3.11/site-packages/particula/data/merger.py:182[0m, in [0;36mstream_add_data[0;34m(stream, time_new, data_new, header_check, header_new)[0m
[1;32m    180[0m     sorted_time_index [38;5;241m=[39m np[38;5;241m.[39margsort(stream[38;5;241m.[39mtime)
[1;32m    181[0m     stream[38;5;241m.[39mtime [38;5;241m=[39m stream[38;5;241m.[39mtime[sorted_time_index]
[0;32m--> 182[0m     stream[38;5;241m.[39mdata [38;5;241m=[39m [43mstream[49m[38;5;241;43m.[39;49m[43mdata[49m[43m[[49m[43m:[49m[43m,[49m[43m [49m[43msorted_time_index[49m[43m][49m
[1;32m    183[0m [38;5;28;01mreturn[39;00m stream

[0;31mMemoryError[0m: Unable to allocate 35.0 GiB for an array with shape (68551, 68551) and data type float64

